[["index.html", "MATH5714 Linear Regression, Robustness and Smoothing Preface", " MATH5714 Linear Regression, Robustness and Smoothing Jochen Voss University of Leeds, Semester 1, 2021–22 Preface From previous modules we know how to fit a regression line through points \\((x_1, y_1), \\ldots, (x_n, y_n) \\in\\mathbb{R}^2\\). The underlying model here is described by the equation \\[\\begin{equation*} y_i = \\alpha + \\beta x_i + \\varepsilon_i \\end{equation*}\\] for all \\(i \\in \\{1, 2, \\ldots, n\\}\\), and the aim is to find values for the intercept \\(\\alpha\\) and the slope \\(\\beta\\) such that the residuals \\(\\varepsilon_i\\) are as small as possible. This procedure, linear regression, and its extensions are discussed in the level 3 component of the module. In the level 5 component of this module, we will discuss “smoothing” which is a technique which can be used when linear models are no longer appropriate for the data. An example of such a situation is illustrated in figure 1. Figure 1: An illustration of a data set where a linear (straight line) model is not appropriate. The data represents a series of measurements of head acceleration in a simulated motorcycle accident, used to test crash helmets (the mcycle dataset from the MASS R package). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
